{
    "metadata": {
        "kernelspec": {
            "name": "pyspark3kernel",
            "display_name": "PySpark3"
        },
        "language_info": {
            "name": "pyspark3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 3
            },
            "pygments_lexer": "python3"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Model Building - Import the training and test data\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "import os\nimport pprint\nimport numpy as np\nimport os\nimport pprint\nimport numpy as np\nimport pandas as pd\n\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\ntrain_data_path = \"/spark_ml/AdultCensusIncomeTrain\"\ntest_data_path = \"/spark_ml/AdultCensusIncomeTest\"\n\ntrain = spark.read.orc(train_data_path)\ntest = spark.read.orc(test_data_path)\n\nprint(\"train: ({}, {})\".format(train.count(), len(train.columns)))\nprint(\"test: ({}, {})\".format(test.count(), len(test.columns)))\n\ntrain.printSchema()\n",
            "metadata": {
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "train: (24469, 3)\ntest: (8092, 3)\nroot\n |-- age: integer (nullable = true)\n |-- hours_per_week: integer (nullable = true)\n |-- income: string (nullable = true)",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": "# Model building - Encode features and Build Model",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "label = \"income\"\nreg = 0.1\nprint(\"Regularization Rate is {}.\".format(reg))\n\n# create a new Logistic Regression model.\nlr = LogisticRegression(regParam=reg)\n\ndtypes = dict(train.dtypes)\ndtypes.pop(label)\n\nsi_xvars = []\nohe_xvars = []\nfeatureCols = []\nfor idx,key in enumerate(dtypes):\n    if dtypes[key] == \"string\":\n        featureCol = \"-\".join([key, \"encoded\"])\n        featureCols.append(featureCol)\n        \n        tmpCol = \"-\".join([key, \"tmp\"])\n        # string-index and one-hot encode the string column\n        #https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/ml/feature/StringIndexer.html\n        #handleInvalid: Param for how to handle invalid data (unseen labels or NULL values). \n        #Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), \n        #or 'keep' (put invalid data in a special additional bucket, at index numLabels). Default: \"error\"\n        si_xvars.append(StringIndexer(inputCol=key, outputCol=tmpCol, handleInvalid=\"skip\")) #, handleInvalid=\"keep\"\n        ohe_xvars.append(OneHotEncoder(inputCol=tmpCol, outputCol=featureCol))\n    else:\n        featureCols.append(key)\n\n# string-index the label column into a column named \"label\"\nsi_label = StringIndexer(inputCol=label, outputCol='label')\n\n# assemble the encoded feature columns in to a column named \"features\"\nassembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n\n# put together the pipeline\nstages = []\nstages.extend(si_xvars)\nstages.extend(ohe_xvars)\nstages.append(si_label)\nstages.append(assembler)\nstages.append(lr)\npipe = Pipeline(stages=stages)\n\n# train the model\nmodel = pipe.fit(train)\nprint(model)\nmodel.stages\n",
            "metadata": {
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Regularization Rate is 0.1.\nPipelineModel_49cfbacdb54dd44bcca2\n[StringIndexer_4e5ab09117dc68a07eae, VectorAssembler_43b7be097576e3659c49, LogisticRegression_42b491b66df1978b6ebc]",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": "# Model Building - Select the best model",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "\nregs = np.arange(0.0, 1.0, 0.2)\n\nparamGrid = ParamGridBuilder().addGrid(lr.regParam, regs).build()\ncv = CrossValidator(estimator=pipe, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cv.fit(train)\n\nmodel = cvModel.bestModel",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": "# Model Evaluation",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# make prediction\npred = model.transform(test)\nprint(pd.DataFrame(pred.take(10)).to_string())\n\n# evaluate. note only 2 metrics are supported out of the box by Spark ML.\nbce = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\nau_roc = bce.setMetricName('areaUnderROC').evaluate(pred)\nau_prc = bce.setMetricName('areaUnderPR').evaluate(pred)\n\nprint(\"Area under ROC: {}\".format(au_roc))\nprint(\"Area Under PR: {}\".format(au_prc))",
            "metadata": {
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "    0   1      2    3             4                                          5                                           6    7\n0  17   4  <=50K  0.0   [4.0, 17.0]    [3.984203061099825, -3.984203061099825]  [0.9817326384088789, 0.018267361591121044]  0.0\n1  17   5  <=50K  0.0   [5.0, 17.0]    [3.935897389723122, -3.935897389723122]  [0.9808458778128771, 0.019154122187122896]  0.0\n2  17   5  <=50K  0.0   [5.0, 17.0]    [3.935897389723122, -3.935897389723122]  [0.9808458778128771, 0.019154122187122896]  0.0\n3  17   6  <=50K  0.0   [6.0, 17.0]  [3.8875917183464184, -3.8875917183464184]  [0.9799169513950979, 0.020083048604902023]  0.0\n4  17   6  <=50K  0.0   [6.0, 17.0]  [3.8875917183464184, -3.8875917183464184]  [0.9799169513950979, 0.020083048604902023]  0.0\n5  17   8  <=50K  0.0   [8.0, 17.0]  [3.7909803755930116, -3.7909803755930116]  [0.9779248519533819, 0.022075148046618136]  0.0\n6  17   8  <=50K  0.0   [8.0, 17.0]  [3.7909803755930116, -3.7909803755930116]  [0.9779248519533819, 0.022075148046618136]  0.0\n7  17   9  <=50K  0.0   [9.0, 17.0]  [3.7426747042163084, -3.7426747042163084]   [0.9768576056063788, 0.02314239439362117]  0.0\n8  17   9  <=50K  0.0   [9.0, 17.0]  [3.7426747042163084, -3.7426747042163084]   [0.9768576056063788, 0.02314239439362117]  0.0\n9  17  10  <=50K  0.0  [10.0, 17.0]    [3.694369032839605, -3.694369032839605]  [0.9757400421084974, 0.024259957891502638]  0.0\nArea under ROC: 0.7364507807436806\nArea Under PR: 0.3950675919086818",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": "# Model Persistence",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "##NOTE: by default the model is saved to and loaded from path\n\nmodel_name = \"AdultCensus.mml\"\nmodel_fs = \"/spark_ml/\" + model_name\n\nmodel.write().overwrite().save(model_fs)\nprint(\"saved model to {}\".format(model_fs))\n\n\n# load the model file (from dbfs)\nmodel2 = PipelineModel.load(model_fs)\nassert str(model2) == str(model)\nprint(\"loaded model from {}\".format(model_fs))",
            "metadata": {
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "saved model to /spark_ml/AdultCensus.mml\nloaded model from /spark_ml/AdultCensus.mml",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        }
    ]
}