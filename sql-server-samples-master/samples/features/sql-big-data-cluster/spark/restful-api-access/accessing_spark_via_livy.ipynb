{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Using Spark from Livy end point\r\nThe samples demostrates using spark service via the livy end point. The sample uses the python request library to access the livy interface. \r\nLivy API details are available at https://livy.incubator.apache.org/docs/latest/rest-api.html\r\n** Note : The image here may not be visible dues to markdown bug. Please change path here to full path to view the image.\r\n<img src = \"./spark_from_livy.jpg\" style=\"float: center;\" alt=\"drawing\" width=\"900\">\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "## Using python requests library to access restful APIs",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "import json, pprint, requests, textwrap\r\nfrom requests.auth import HTTPBasicAuth\r\nprint(\"Get username and email \")\r\nprint(\"---------------------- \")\r\n\r\n#Basic test for request\r\nimport requests\r\n\r\nr = requests.get('https://jsonplaceholder.typicode.com/users')\r\nr.encoding = 'utf-8'\r\nret_json = r.json()\r\n\r\n\r\nfor user in ret_json:\r\n    print(user['username'] , user['email'])\r\n\r\n#print(r.json()) \r\n\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Get username and email \n---------------------- \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Bret Sincere@april.biz\nAntonette Shanna@melissa.tv\nSamantha Nathan@yesenia.net\nKarianne Julianne.OConner@kory.org\nKamren Lucio_Hettinger@annie.ca\nLeopoldo_Corkery Karley_Dach@jasper.info\nElwyn.Skiles Telly.Hoeger@billy.biz\nMaxime_Nienow Sherwood@rosamond.me\nDelphine Chaim_McDermott@dana.io\nMoriah.Stanton Rey.Padberg@karina.biz\n"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": "## Livy APIs to fetch running sessions and sesssion state",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "import json, pprint, requests, textwrap\r\nfrom requests.auth import HTTPBasicAuth\r\n\r\n#Diabling exception to avoid the https verificatin warning\r\nimport requests.packages.urllib3 as urllib3\r\nimport urllib3.exceptions as urllib3_exceptions       \r\nurllib3.disable_warnings(urllib3_exceptions.InsecureRequestWarning)\r\n\r\n\r\n#Change host per your confirgration                               \r\nhost = \"https://<ip>:<port>/gateway/default/livy/v1\"\r\n\r\n#Livy interface as per https://livy.incubator.apache.org/docs/latest/rest-api.html#session\r\n\r\n# Construct Request - Get a list of current spark sessions.\r\nsessions_url = host + \"/sessions\"\r\n\r\n# Common headers for all requests.\r\n# Auth header\r\nauth = HTTPBasicAuth(\"***\", \"***\")\r\n# Content Type\r\nheaders = {'Content-Type': 'application/json'}\r\n\r\ndata = {\r\n        'from': 0, \r\n        'size': 10\r\n       }\r\nr = requests.get(sessions_url, data=json.dumps(data), headers=headers, auth=auth, verify=False)\r\n\r\nresponse_body = r.json()\r\n\r\nprint(\"Sessions fetched starting \", response_body['from'])\r\nprint(\"Number of session fetched\", response_body['total'])\r\nsession_list = response_body['sessions']\r\n\r\nfor session in session_list:\r\n    print(\"The session {0} has a state {1} \".format(session['id'],session['state']))\r\n\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Sessions fetched starting  0\nNumber of session fetched 1\nThe session 10 has a state idle \n"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": "## Create a new Spark session and query state",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "#Create a new Spark session\r\ndata = {\r\n    'kind':'pyspark'\r\n}\r\n\r\nr = requests.post(sessions_url, data=json.dumps(data), headers=headers, auth=auth, verify=False)\r\nresponse_body = r.json()\r\n\r\nsession_id = response_body['id']\r\nsession_state = response_body['state']\r\nprint(\"Spark session {0} created. Current state is {1}\".format(session_id,session_state))\r\ncreated_session_url = r.headers['location']\r\n\r\n\r\n\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Spark session 13 created. Current state is starting\n"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": "#Query information about the session we just created\r\nthis_session_url = host + created_session_url\r\nprint(\"this_session_url\", this_session_url)\r\n\r\nr = requests.get(this_session_url, headers=headers,auth=auth, verify=False)\r\npprint.pprint(r.json())",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "this_session_url https://13.91.32.53:30443/gateway/default/livy/v1/sessions/13\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "{'appId': 'application_1560270944894_0014',\n 'appInfo': {'driverLogUrl': 'http://storage-0-0.storage-0-svc.newaks.svc.cluster.local:8042/node/containerlogs/container_1560270944894_0014_01_000001/root',\n             'sparkUiUrl': 'http://master-0.master-svc:8088/proxy/application_1560270944894_0014/'},\n 'id': 13,\n 'kind': 'pyspark',\n 'log': ['\\t ApplicationMaster RPC port: -1',\n         '\\t queue: default',\n         '\\t start time: 1560880472284',\n         '\\t final status: UNDEFINED',\n         '\\t tracking URL: '\n         'http://master-0.master-svc:8088/proxy/application_1560270944894_0014/',\n         '\\t user: root',\n         '19/06/18 17:54:32 INFO util.ShutdownHookManager: Shutdown hook '\n         'called',\n         '19/06/18 17:54:32 INFO util.ShutdownHookManager: Deleting directory '\n         '/tmp/spark-de7b25a4-1605-4d7f-bef5-c921175c8ae9',\n         '19/06/18 17:54:32 INFO util.ShutdownHookManager: Deleting directory '\n         '/tmp/spark-00164108-299d-4313-b800-04bbfb8c1e5a',\n         '\\nYARN Diagnostics: '],\n 'name': None,\n 'owner': None,\n 'proxyUser': None,\n 'state': 'idle'}\n"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": "## Execute code interactively Spark session and check results",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "\r\n#Execute code interactively in this session using session/<ID>/statements interface\r\n\r\nstatements_url = this_session_url + \"/statements\"\r\npprint.pprint(statements_url)\r\n\r\ndata = {\r\n  'code': \"11+11\"\r\n}\r\n\r\nr = requests.post(statements_url, data=json.dumps(data), headers=headers, auth=auth, verify=False)\r\nprint(\"Respone status code\" ,r.status_code )\r\nprint(\"Response received is \",r.json())\r\nprint(\"Poll URI is \",r.headers['location'])\r\n#response_body = r.json()\r\n\r\n\r\n\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "'https://13.91.32.53:30443/gateway/default/livy/v1/sessions/13/statements'\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Respone status code 201\nResponse received is  {'id': 0, 'code': '11+11', 'state': 'waiting', 'output': None, 'progress': 0.0}\nPoll URI is  /sessions/13/statements/0\n"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "code",
            "source": "# Wait a while before executing this cell. Spark session start up takes time to run your code.\r\nspecific_statement = host + r.headers['location']\r\nprint(\"monitoring url is \", specific_statement)\r\n\r\nr = requests.get(specific_statement, headers=headers, auth=auth, verify=False)\r\nprint(\"Response status is \",r.status_code)\r\nprint(\"Response received is \", pprint.pprint(r.json()))",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "monitoring url is  https://13.91.32.53:30443/gateway/default/livy/v1/sessions/13/statements/0\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Response status is  200\n{'code': '11+11',\n 'id': 0,\n 'output': {'data': {'text/plain': '22'}, 'execution_count': 0, 'status': 'ok'},\n 'progress': 1.0,\n 'state': 'available'}\nResponse received is  None\n"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": "## Execute code in batch",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "#Execute code in batch\r\n#The following uses pi.py from spark source. Please get that file and transer to HDFS /jar folder.\r\nbatch_url = host + \"/batches\"\r\nprint(\"batch_url\", batch_url)\r\n\r\ndata = {\r\n    'file' : '/jar/pi.py'    \r\n}\r\n\r\nr = requests.post(batch_url, data=json.dumps(data), headers=headers, auth=auth, verify=False)\r\nreturned_batch_url = r.headers['location']\r\nprint(\"Respone status code\" , r.status_code)\r\nprint(\"Poll URI is \",returned_batch_url )\r\nprint(\"Response is \", pprint.pprint(r.json()))",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "batch_url https://13.91.32.53:30443/gateway/default/livy/v1/batches\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Respone status code 201\nPoll URI is  /batches/1\n{'appId': None,\n 'appInfo': {'driverLogUrl': None, 'sparkUiUrl': None},\n 'id': 1,\n 'log': ['stdout: ', '\\nstderr: ', '\\nYARN Diagnostics: '],\n 'name': None,\n 'state': 'starting'}\nResponse is  None\n"
                }
            ],
            "execution_count": 15
        },
        {
            "cell_type": "code",
            "source": "#Check results of executed code\r\nspecific_batch = host + returned_batch_url\r\nprint(\"specific batch request \",specific_batch)\r\n\r\nr = requests.get(specific_batch,headers=headers, auth=auth, verify = False)\r\nprint(\"Response status is \",r.status_code)\r\nprint(\"Response received is \", pprint.pprint(r.json()))",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "specific batch request  https://13.91.32.53:30443/gateway/default/livy/v1/batches/1\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Response status is  200\n{'appId': None,\n 'appInfo': {'driverLogUrl': None, 'sparkUiUrl': None},\n 'id': 1,\n 'log': ['stdout: ',\n         '19/06/18 17:57:32 WARN util.NativeCodeLoader: Unable to load '\n         'native-hadoop library for your platform... using builtin-java '\n         'classes where applicable',\n         '\\nstderr: ',\n         '\\nYARN Diagnostics: '],\n 'name': None,\n 'state': 'starting'}\nResponse received is  None\n"
                }
            ],
            "execution_count": 16
        }
    ]
}